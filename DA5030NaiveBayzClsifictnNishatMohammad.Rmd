---
title: "Use Naive Bayes for Classification"
author: Dr. Nishat Mohammad
date: 02/14/2024
output:
  pdf_document:
    latex_engine: xelatex
  html_document:
    toc: true
    toc_float: true
    code_folding: show
---
Load some needed packages
```{r loading_packages}
# Text mining
library(tm)
# Text stemming
library(SnowballC)
# Word cloud visualization
library(wordcloud)
# Naive Bayes Model
library(e1071)

#library(gmodels)

```

## 1. Exploring and Preparing the Data
### 1.1. Loading the data for SMS Spam

```{r loading_data}
# Read csv file into sms_dt
sms_dt <- read.csv("spammsg.csv")

# Look at the structure of the data
str(sms_dt)

# Look at the first few rows of the data
head(sms_dt)

# A few more lines for my understanding
# Look at the dimensions
dim(sms_dt)
# Check for missing values
any(is.na(sms_dt))

```
### 1.2. Factoring Categorical Variables.  

```{r factoring}
# Factor type
sms_dt$type <- factor(sms_dt$type)

# Look at the structure
str(sms_dt$type)

```
Categorical variables are to be factored and in this data the type variable is categorical diving the data into ham and spam categories.  
After factoring the ham category is assigned to 1 and spam to 2.  

```{r view_type_column_distribution}
# Look at the distribution of ham and spam in a table
table(sms_dt$type)
```
We check the overall distribution of spam and ham and find 747 an 4827 values respectively.  


## 2. Data Preparation.  

### 2.1. Cleaning and Standardizing Text Data.  

#### 2.1.1. Text Mining and Natural Language Processing.  

```{r create_corpus}
# Create a VCorpus Object
sms_dt_corpus <- VCorpus(VectorSource(sms_dt$text))
print(sms_dt_corpus)

# Look at the first two documents in general
inspect(sms_dt_corpus[1:2])

# Look at the text in the first document
sms_dt_first_doc <- as.character(sms_dt_corpus[[1]])
#sms_dt_first_doc

# Look at the text for the first 2 docs
sms_dt_1st2nd_doc <- lapply(sms_dt_corpus[1:2], as.character)
#sms_dt_1st2nd_doc
```
The `VCorpus()` function from the tm Package in R is used for text mining and natural language processing, it takes a vector of text values and returns a Vcorpus object which is a collection of multiple text documents. For our data we can see by printing the VCorpus Object (sms_dt_corpus) is printed to find that we have 5574 documents. SO it acts as a container for the text data and allows for use of more methods and functions to manipulate to our choices.   
Wrapping the Vcorpus Object in `inspect()` function we can see more details about the data, looking at the first 2 documents in the corpus.  
There are no copus_specific metadata and no indexed attributes for the metadata.  
Both doucments are Plain Text  with 7 metadata attributes, the first one has 111 characters in the content while the second document has 29 characters in its content.
Looking at the text in the first document using the `as.inspect()` function, let us look at it below:  

`r paste0('"',sms_dt_first_doc,'"')`.  

Looking at the text for the first two documents by using `lapply()` function to apply the `as.character()` function on a list of the first two documents from the corpus. Please view them below:  

`r paste0('"',sms_dt_1st2nd_doc,'"')`.  

#### 2.1.2. Clean, Standaradize and Transform the data.  

```{r transform_to_lowercase}
# Transform all characters to lower case
sms_dt_corpus_clean <- tm_map(sms_dt_corpus, content_transformer(tolower))
# Look at the first document in cleaned data
sms_dt_cleand_first_doc <- as.character(sms_dt_corpus_clean[[1]])
#sms_dt_cleand_first_doc
```
Converting all letters to lower case was done by wrapping the corpus in the `tm_map()` function and specifying `tolower` in the `content_transformer()` function.  
After transforming to lower cases the first document has all lower case alphabets as was expected and looks like this:  

`r paste0('"',sms_dt_cleand_first_doc,'"')`.  

The `content_transformer()` function can be used for various purposes, from making abbreviations to full forms to finding group of words or creating content based features as part of feature engineering.  

```{r take_off_numbers}
# Take numbers off form data
sms_dt_corpus_clean <- tm_map(sms_dt_corpus_clean, removeNumbers)

```

Passing the cleaned orpus to `tm_map` function with `removeNumbers` option takes off the numbers in the data.  

```{r take_off_fillers}
# Remove filler words
sms_dt_corpus_clean <- tm_map(sms_dt_corpus_clean, removeWords, stopwords())
```
Wrapping the corpus in `tm_map()` function with the `removeWords` option and `stopwords()` function takes off the filler words in the data.  

```{r take_off_punctuatns}
# Take off punctuations
sms_dt_corpus_clean <- tm_map(sms_dt_corpus_clean, removePunctuation)

# Function to adjy=ust any settings in the remove punctuation tasks
replacePunctuation <- function(x) {
    gsub("[[:punct:]]+", " ", x)
}

```
Using the `removePunctuation` option in `tm_map()` function takes off the punctuations in the data.  The punctuations to be removed can be specified using regex through the gsub() function as shown in the code above.   

```{r text_stemming}
# remove same words in different tenses or forms
sms_dt_corpus_clean <- tm_map(sms_dt_corpus_clean, stemDocument)

```
Using the `stemDocument` option in `tm_map()` removes various forms of the same word such as plurals, tenses among others.  

```{r }
sms_dt_corpus_clean <- tm_map(sms_dt_corpus_clean, stripWhitespace)

```
We take care of white spaces using the `stripWhitespace` option in `t_map()` function.  

```{r final_cleaned_data}
# Look at the cleaned data again
print(sms_dt_corpus_clean)

# Look at the first two docs
inspect(sms_dt_corpus_clean[1:2])
sms_dt_clean1st2nd_doc <- lapply(sms_dt_corpus_clean[1:2], as.character)
#sms_dt_clean1st2nd_doc
```

After these steps we have arrived at the following for the first 2 docments:

`r paste0('"',sms_dt_clean1st2nd_doc,'"')`.  

### 2.2. Splitting Text Document into Words.  

```{r data_preparation}
# Create a DTM
sms_dt_dtm <- DocumentTermMatrix(sms_dt_corpus_clean)
sms_dt_dtm

```
 The `DocumentTermMatrix()` function  from the `tm` package is  used to create a sparse matrix called the document-term matrix (DTM) by taking a corpus object and making the documents the rows and the words will become the columns.  
The cleaned data was passed to the function and can be viewed above.  

```{r aternative_method}
# Function to carry out all the earlier steps
sms_dt_dtm2 <- DocumentTermMatrix(sms_dt_corpus, control = list(
    tolower = TRUE,
    removeNumbers = TRUE,
    stopwords = TRUE,
    removePunctuation = TRUE,
    stemming = TRUE
))
sms_dt_dtm2
```

The original corpus can be passed to the function and options specified therein  to clean the data this can cause a slight differenc edue to the sequence of cleaning steps. Please view the corpus cleaned with the `DocumentTermMatrix()` function above.


### 2.3. Creating Training and Test Sets.  

```{r Training_and_test_sets}
# Get 75% of the rows
tot_rows <- nrow(sms_dt_dtm)

# Limits for training and test
train_limit <- round(0.75 * tot_rows, 0) 
test_limit <- tot_rows - train_limit


# Training set
sms_dt_dtm_train <- sms_dt_dtm[1:train_limit, ]
# Test set
sms_dt_dtm_test <- sms_dt_dtm[(train_limit+1):test_limit, ]

# Labels
sms_dt_train_labels <- sms_dt[1:train_limit, ]$type
sms_dt_test_labels <- sms_dt[(train_limit+1):test_limit, ]$type

# Check the distribution between ham and spam 
prop.table(table(sms_dt_train_labels))

```
 Here the data was split into training and test sets based on 75:25 ratio respectively. The proportion for ham and spam were checked using the `prop.table()` function. The ham got 86% and the spam took about 13%.  

## 3. Visualization of text data Using Word Clouds.  

### 3.1. Word cloud for the cleaned data
```{r word_clouds_clean_data}
wordcloud(sms_dt_corpus_clean, min.freq = 50, random.order = FALSE, colors = "purple", vfont=c("gothic english","plain"))


```
The figure above shows all the words in the data after cleaning

### 3.2. Word Cloud for Spam.  

```{r word_cloud_ham, warning=FALSE}
# Sample spam out of the main data
spam_dt <- subset(sms_dt, type == "spam")
wordcloud(spam_dt$text, max.words = 40, scale = c(3, 0.5), colors = "blue", vfont=c("gothic english","plain"))

```
The figure above shows the word cloud for the spam data alone. R has dropped some documents  probably due to its own cleaning mechanisms. The most frequent words here are `call, free, txt, mobile`.  

### 3.3. Word Cloud for Ham.  

```{r word_cloud_spam}
# Sample ham form main data
ham_dt <- subset(sms_dt, type == "ham")
wordcloud(ham_dt$text, max.words = 40, scale = c(3, 0.5), colors = "red", vfont=c("gothic english","plain"))
intersect(ham_dt,spam_dt)
```
This figure shows the ham data  in a word cloud. R has dropped documents here as well. The most frequent words are `can, get, will, just, know`.  
Thus Naive Bayes has picked up key words form the data.  


## 4. More Data Preparation by Creating Indicator Features for frequent words.  
### 4.1 The frequent words
```{r frequent_words}
# Get the frequent words in training set
sms_dt_freq_words <- findFreqTerms(sms_dt_dtm_train, 5)
# Look at the structure
str(sms_dt_freq_words)

```
Frequent words are extracted using the training dtm data and the structure can be seen above. There are 861 frequent words.  

### 4.2. Assign features to train and test set.  

```{r split_frequent_words}
sms_dt_dtm_freq_train <- sms_dt_dtm_train[ , sms_dt_freq_words]
print(sms_dt_dtm_freq_train)
sms_dt_dtm_freq_test <- sms_dt_dtm_test[ , sms_dt_freq_words]
print(sms_dt_dtm_freq_test)

```
The training set has 4180 documents and the test set has 2788 documents.  

### 4.3. Change Numeric Naive Bayes to Categorical.  

```{r Check_strings}
convert_counts <- function(x) {
    x <- ifelse(x > 0, "Yes", "No")
}

sms_traind <- apply(sms_dt_dtm_freq_train, MARGIN = 2,
    convert_counts)
sms_testd  <- apply(sms_dt_dtm_freq_test, MARGIN = 2,
    convert_counts)
```
Before modelling, the numeric values in the train and test dtms were changed to Yes for 0 and No for 1 by using the covert function and applying it over the columns of the frequency train and test sets by using `MARGIN = 2`. This makes the data uniform in class.  



## 5. Train Naive Bayes Model on the Data.  

```{r naive_Bayes_model}
# Use naive bayes from e1071 package
sms_dt_classifier <- naiveBayes(sms_traind, sms_dt_train_labels)
```
To Create the model, the `naiveBayes()` function from the `e1071` package is used in the code chunk above by wrapping the frequency train set and the train set labels in it.  


## 6. Evaluate Model
### 6.1. Apply the Test Data for Evaluation
```{r model_evaluation}
sms_dt_test_predict <- predict(sms_dt_classifier, sms_testd)

```
A vital step in modelling is evaluation and here it has been carried out by using the `predict()` function with the model and the frequency test set passed to it.  

### 6.2. Create Cross Table (Confusion Table).  

```{r confusion_Table}
# Load package
library(gmodels)

# Get cross table
CrossTable(sms_dt_test_predict,
           sms_dt_test_labels,
           prop.chisq = FALSE, 
           prop.c = FALSE, 
           prop.r = FALSE,
           dnn = c('predicted', 'actual'))

```
The cross table above shows actual ham are 2425 and the model predicted a total of 2457 ham, slightly higher to take note of.  
The actual spam are 363 but the model predicted 331 spam, slightly lower, implying that the model is picking spam as ham incorrectly.  
Let us get some probabilties with the code chunk below.  

```{r examine_crosstable1}
# Probability the model predicts spam 
Pspam1 <- (5 +37)/2788
# Probability the model predicts spam incorrectly
PIncorrect_spam1 = 37/363
# Probability the model predicts ham
Pham1 <- (2420+326)/2788
# Probability the model predicts ham incorrectly
PIncorrect_ham1 = 5/2425
# Consider ham is the positive observation
TP1<- 2420 
TN1 <-326 
FP1 <- 37
FN1 <- 5
total_obs <- 2788
# Accuracy of model
Accuracy1 <- (TP1 +TN1)/ total_obs
Sensitivity1 <- TP1/(TP1+FN1)
Specifictiy1 <- TN1/(TN1 + FP1)

```

The probability that this model will predict spam is:  
P(spam) = `r paste0('"',Pspam1,'"')`.  
The probability that this model will predict ham is:  
P(ham) = `r paste0('"',Pham1,'"')`.  

The probability that the model will predict ham incorrectly is:  
Incorrect ham = `r paste0('"',PIncorrect_ham1,'"')`.  
The probability that the model will predict spam incorrectly is:  
Incorrect spam = `r paste0('"',PIncorrect_spam1,'"')`.  

Accuracy of this model is `r paste0('"',Accuracy1,'"')`.  
Sensitivity of this model is `r paste0('"',Sensitivity1,'"')`.  
Specificity of this model is `r paste0('"',Specifictiy1,'"')`.  

## 7. Improve Model Performance.  

```{r improved_model}
# Train new model
sms_dt_classifier2 <- naiveBayes(sms_traind, sms_dt_train_labels, laplace = 1)

# Test the new model
sms_dt_test_pred2 <- predict(sms_dt_classifier2, sms_testd)

# Create cross table

CrossTable(sms_dt_test_pred2, sms_dt_test_labels,
    prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
    dnn = c('predicted', 'actual'))

```
The cross table above is created after using la Place constant to improve prediction.  
The total number of ham predicted by this second model is 2420 where as the actual are 2425.
The total number of spam predicted by the second model are 368 whereas the actual are 363.  
Let us examine the corss table with the code chunk below.  

```{r examine_cross_table2}
# Consider ham is the positive observation
TP2<- 2200 
TN2 <-343 
FP2 <- 20
FN2 <- 25

# Accuracy of model
Accuracy2 <- (TP2 +TN2)/ total_obs
Sensitivity2 <- TP2/(TP2+FN2)
Specifictiy2 <- TN2/(TN2 + FP2)

```

Accuracy of the second model is `r paste0('"',Accuracy2,'"')`.  
Sensitivity of the second model is `r paste0('"',Sensitivity2,'"')`.  
Specificity of the second model is `r paste0('"',Specifictiy2,'"')`.  

```{r compare_model_performance}
# Organize data
analytic_methods <- c("Accuracy", "Sensitivity", "Specificity")
mod1data <- c(Accuracy1,Sensitivity1, Specifictiy1)
mod2data <- c(Accuracy2, Sensitivity2,Specifictiy2)
# Tabulate data
compare_models_table <- data.frame(analytic_methods,mod1data, mod2data)
knitr::kable(compare_models_table)

```
From the table above, although both models are highly competitive on the accuracy and sensitivity and specificity:  
The second model surpasses the first model on specificity alone.  
The first model remains more accurate than the second and also more sensitive.  
I thought about the word "now" being common to both ham and spam categories, and if it would affect the outcome of the Naive Bayes prediction, but since it is only one word that is common I inferred that it would not be relevant enough to consider this as blocker to accuracy of the models.  
Both models can be relied upon for different purposes though based on the business needs and priorities, since they are both highly accurate. 
